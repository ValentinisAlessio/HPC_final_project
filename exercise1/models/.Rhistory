# Check by fixing p =0.5
llik_bin(0.5,y)
llik_bin2(0.5,y)
# Maximum likelihood estimate
MLEp  <- mean(y)
MLEp
# Log-likelihhod evaluated at the maximum
llik_bin(MLEp, y)
# Check
pgrid <- seq(0.01, 0.99, by = 0.01)
pgrid[which(llik_bin2(pgrid, y) == max(llik_bin2(pgrid, y)))]
# Plot of the log-likelihood function
curve(llik_bin2(theta=x, data = y), 0, 1,
xlab= expression(p), ylab = expression(l(p)),
main = "Log-likelihood function")
abline(v = p, col = "red")
abline(v = MLEp, col = "blue")
legend("topleft", legend = c(expression(p),
expression(hat(p))),
col = c("red","blue"), lty = c(1,1))
# Plot of the log-likelihood function (after vectorization of the function llik_bin)
llik_bin_v <- Vectorize(llik_bin, 'theta')
curve(llik_bin_v(theta=x, data = y), 0, 1,
xlab= expression(p), ylab = expression(l(p)),
main = "Log-likelihood function")
abline(v = p, col = "red")
abline(v = MLEp, col = "blue")
legend("topleft", legend = c(expression(p),
expression(hat(p))),
col = c("red","blue"), lty = c(1,1))
# Note on vectorization
llik_bin(c(0.5,0.99), y) # Wrong
llik_bin2(c(0.5,0.99), y) # Correct
llik_bin_v(c(0.5,0.99), y) # Correct
# logit(p)
psi <- function(theta){
log(theta/(1-theta))
}
# inverse of logit(p)
theta <- function(psi){
exp(psi)/(1+exp(psi))
}
# log-likelihood under the reparametrization
llik_bin_rep <- function(param, data) llik_bin2(theta(param), data)
# Plot of the log-likelihood
curve(llik_bin_rep(param=x, data = y), -10, 10,
xlab= expression(psi), ylab = expression(l(psi)),
main = "Log-likelihood function")
abline(v = psi(p), col = "red")
abline(v = psi(MLEp), col = "blue")
legend("topleft", legend = c(expression(psi),
expression(hat(psi))),
col = c("red", "blue"), lty = c(1, 1))
## Monte Carlo simulation to assess the normal approximation of the MLE
set.seed(1234)
R <- 5000
p <- 0.6
n <- 1000
samples <- rep(0, R)
for(i in 1:R){
samples[i] <- mean(rbinom(n, 1, p))
}
hist(samples, freq = F, nclass = 30, main = "")
curve(dnorm(x, mean = p, sd = sqrt((p * (1 - p)/n))),
lwd = 2, xlab = "", ylab = "", add = T)
hist(psi(samples), freq = F, nclass = 30, main = "")
curve(dnorm(x, mean = psi(p), sd = 1/sqrt((p * (1 - p)*n))),
lwd = 2, xlab = "", ylab = "", add = T)
par(mfrows=c(2,1))
hist(samples, freq = F, nclass = 30, main = "")
curve(dnorm(x, mean = p, sd = sqrt((p * (1 - p)/n))),
lwd = 2, xlab = "", ylab = "", add = T)
hist(psi(samples), freq = F, nclass = 30, main = "")
curve(dnorm(x, mean = psi(p), sd = 1/sqrt((p * (1 - p)*n))),
lwd = 2, xlab = "", ylab = "", add = T)
par(mfrows=c(1,2))
hist(samples, freq = F, nclass = 30, main = "")
par(mfrow=c(1,2))
hist(samples, freq = F, nclass = 30, main = "")
curve(dnorm(x, mean = p, sd = sqrt((p * (1 - p)/n))),
lwd = 2, xlab = "", ylab = "", add = T)
hist(psi(samples), freq = F, nclass = 30, main = "")
curve(dnorm(x, mean = psi(p), sd = 1/sqrt((p * (1 - p)*n))),
lwd = 2, xlab = "", ylab = "", add = T)
################################################
## Weibull model                               #
################################################
# Plot weibull density function by varying the shape and the scale paramter
sh_val <- c(0.5, 1, 1, 1.5, 5)
sc_val <- c(1, 1, 2, 1, 1)
colours <- c("black", "red", "blue", "green", "purple")
curve(dweibull(x, shape = sh_val[1], scale = sc_val[1]), from = 0, to = 3,
ylab = expression("f(y;" ~ gamma ~"," ~ beta ~")"), xlab = "y")
for(i in 2 : length(sh_val)){
curve(dweibull(x, shape = sh_val[i], scale = sc_val[i]),
add = TRUE, col = colours[i])
}
legend("topright", legend = c(expression(gamma == 0.5 * ";" ~ beta == 1),
expression(gamma == 1 * ";" ~ beta == 1),
expression(gamma == 1 * ";" ~ beta == 2),
expression(gamma == 1.5 * ";" ~ beta == 1),
expression(gamma == 5 * ";" ~ beta == 1)),
col = colours, lty = rep(1, 5), cex = 0.8, box.lty = 0)
par(mfrow=c(1,1))
################################################
## Weibull model                               #
################################################
# Plot weibull density function by varying the shape and the scale paramter
sh_val <- c(0.5, 1, 1, 1.5, 5)
sc_val <- c(1, 1, 2, 1, 1)
colours <- c("black", "red", "blue", "green", "purple")
curve(dweibull(x, shape = sh_val[1], scale = sc_val[1]), from = 0, to = 3,
ylab = expression("f(y;" ~ gamma ~"," ~ beta ~")"), xlab = "y")
for(i in 2 : length(sh_val)){
curve(dweibull(x, shape = sh_val[i], scale = sc_val[i]),
add = TRUE, col = colours[i])
}
legend("topright", legend = c(expression(gamma == 0.5 * ";" ~ beta == 1),
expression(gamma == 1 * ";" ~ beta == 1),
expression(gamma == 1 * ";" ~ beta == 2),
expression(gamma == 1.5 * ";" ~ beta == 1),
expression(gamma == 5 * ";" ~ beta == 1)),
col = colours, lty = rep(1, 5), cex = 0.8, box.lty = 0)
## Log-likelihood by using the dweibull function
n_logLik_Weib <- function(param, data){
-sum(dweibull(data, shape = param[1], scale = param[2], log = TRUE))
}
## Log-likelohood built manually
n_logLik_Weib2 <- function(param, data){
n <- length(data)
res <- n * log(param[1]) -
n * param[1] * log(param[2]) +
param[1] * sum(log(data)) -
sum((data/param[2])^param[1]) -
sum(log(data))
return( -res )
}
n_logLik_Weib(param= c(10,10), data=y)
n_logLik_Weib2(param= c(10,10), data=y)
#######################################################
# Weibull model example: failure times of light bulbs #
#######################################################
# Data
y <- c(173.187, 139.334, 140.205, 139.261, 118.176, 138.105, 193.096,
163.589, 136.288, 146.226, 134.261, 144.331, 160.262, 107.985, 159.651)
n_logLik_Weib(param= c(10,10), data=y)
n_logLik_Weib2(param= c(10,10), data=y)
# Define a parameter grid to plot the log-likelihood
gamma <- seq(0.1, 15, length = 100)
beta <- seq(100, 200, length = 100)
parvalues <- expand.grid(gamma, beta)   #Cartesian product
# obtain the log-likelihood values  for each point of the grid
n_llikvalues <- apply(parvalues, 1, n_logLik_Weib, data = y)
llikvalues <- matrix(-n_llikvalues,
nrow = length(gamma), ncol = length(beta),
byrow = FALSE)
parvalues
parvalues <- expand.grid(gamma, beta)   #Cartesian product
# obtain the log-likelihood values  for each point of the grid
n_llikvalues <- apply(parvalues, 1, n_logLik_Weib, data = y)
llikvalues <- matrix(-n_llikvalues,
nrow = length(gamma), ncol = length(beta),
byrow = FALSE)
# Define the confidence levels
conf_levels <- c(0, 0.5, 0.75, 0.9, 0.95, 0.99)
par(mfrow = c(1, 2))
# contour plot
contour(gamma, beta, llikvalues - max(llikvalues),
levels = -qchisq(conf_levels, 2)/2,
xlab = expression(gamma), ylab = expression(beta),
labels = as.character(conf_levels))
title("Weibull relative log likelihood")
# image plot
image(gamma, beta, llikvalues - max(llikvalues),
zlim = c(-6, 0), col = terrain.colors(20),
xlab = expression(gamma), ylab = expression(beta))
title("Weibull relative log likelihood")
## Score function
logLik_score_g <- function(x, data){
n <- length(data)
res <- n/x + sum(log(data)) - n * (sum(data^x * log(data))/(sum(data^x)))
return(res)
}
# MLE of gamma: solve the lok-likelihood equation via the uniroot function
gammahat <- uniroot(logLik_score_g, c(1e-5, 15), data = y)$root
gammahat
# MLE of beta, for a fixed value of gamma (the MLE of gamma)
betahat <- mean(y^gammahat)^(1/gammahat)
betahat
# Check if the numerical score is approximately (0,0) at the MLE
library(numDeriv)
grad(c(gammahat, betahat), func = n_logLik_Weib, data = y)
# observed information matrix evaluated at the MLE
n <- length(y)
jhat <- matrix(NA, 2, 2)
jhat[1,1] <- n/gammahat^2 + sum((y/betahat)^gammahat*(log(y/betahat)^2))
jhat[1,2] <- n/betahat -
sum(y^gammahat/(betahat^(gammahat+1)) * (gammahat*log(y/betahat)+1))
jhat[2,1] <- jhat[1,2]
jhat[2,2] <- -n*gammahat/(betahat^2) +
gammahat*(gammahat+1) * sum(y^gammahat)/(betahat^(gammahat+2))
jhat
# Check by using the hessian function of the numDeriv package
hessian(c(gammahat, betahat), func = n_logLik_Weib, data = y)
# Estimate of the std.err of the MLE estimators
mle.se <- sqrt(diag(solve(jhat)))
mle.se
## Confidence regions
## LRT-type based confidence region
par(mfrow = c(1, 2))
contour(gamma, beta, llikvalues - max(llikvalues),
ylab = expression(beta), xlab = expression(gamma),
levels = -qchisq(conf_levels, 2)/2, main = 'LRT',
labels = as.character(conf_levels))
points(gammahat, betahat, col = 2)
## Wald-type based confidence region
weib.y.mle <- c(gammahat, betahat)
wt <-  function(par, jhat){
difftheta <-   as.matrix(weib.y.mle-par)
return(-.5*t(difftheta) %*% jhat %*% difftheta)
}
waldvalues <- apply(parvalues, 1, wt, jhat = jhat)
waldvalues <- matrix(waldvalues, nrow = length(gamma),
ncol = length(beta), byrow = F)
contour(gamma, beta, waldvalues,
ylab = expression(beta), xlab = expression(gamma),
levels = -qchisq(conf_levels,2)/2,
labels = as.character(conf_levels),
col = 2, main = 'WALD', lty = 'longdash')
points(gammahat, betahat, col = 2)
# By using nlm function
#Staring values near to MLE estimate
weib.nlm_start1 <- nlm(f = n_logLik_Weib, p = c(5, 160), data = y, hessian = TRUE)
weib.nlm_start1
#Staring values far to MLE estimate
weib.nlm_start2 <- nlm(f = n_logLik_Weib, p = c(0.1, 0.1), data = y, hessian = TRUE)
weib.nlm_start2
# By using optim function
#Starting values near to MLE estimate
weib.optim_start1 <- optim(par = c(5, 160), fn= n_logLik_Weib, data = y, hessian = TRUE,
method = "L-BFGS-B", lower = rep(1e-7,2), upper = rep(Inf,2))
weib.optim_start1
#Staring values far to MLE estimate
weib.optim_start2 <- optim(par = c(0.1, 0.1), fn = n_logLik_Weib, data = y, hessian = TRUE,
method = "L-BFGS-B", lower = rep(1e-7, 2), upper = rep(Inf,2))
weib.optim_start2
# Reparameterization
theta <- function(omega) exp(omega)
# Negative log-likelihood
n_logLik_Weib_rep <- function(param, data) n_logLik_Weib(theta(param), data)
# Optimize the log-likelihood function by using nlm (also here the are some warnings but the algorithm works)
weib_nlm_start3_rep <- nlm(f = n_logLik_Weib_rep, p = c(0, 0), data = y)
weib_nlm_start3_rep
weib_nlm_start3_rep <- nlm(f = n_logLik_Weib_rep, p = c(2, 5), data = y)
weib_nlm_start3_rep
# Check
theta(weib_nlm_start3_rep$estimate)
weib.nlm_start1$estimate
# Optimize the log-likelihood function by using ucminf
library(ucminf)
weib_nlm_start3_rep_ucminf <- ucminf(f = n_logLik_Weib_rep, p = c(0, 0), data = y)
weib_nlm_start3_rep_ucminf
install.packages("tidyverse")
clear
rm(list=ls())
#Ex 4.44
house <- read.table("dataset/Houses.dat", header = T)
# MLE of the sd is the biased sample sd
s <- sqrt(1/length(house$price) * sum((house$price - mu)^2))
#Ex 4.44
house <- read.table("dataset/Houses.dat", header = T)
house
#Ex 4.44
house <- read.table("dataset/Houses.dat", header = T)
# Population parameters
population_mean <- 72
population_stddev <- 12
# Sample size
n <- 100
num_samples <- 1000  # Number of samples to generate
# Generate random samples and calculate sample means
sample_means <- replicate(num_samples, mean(rnorm(n, mean = population_mean, sd = population_stddev)))
# Create a histogram to visualize the sampling distribution of the sample mean
hist(sample_means, breaks = 30, prob = TRUE, col = "blue", main = "Sampling Distribution of Sample Mean for n = 100")
abline(v = population_mean, col = "red", lty = 2, lwd = 2)
legend("topright", legend = c("Sample Mean Distribution", "Population Mean"), col = c("blue", "red"), lty = c(1, 2))
# Population parameters
population_mean <- 72
population_stddev <- 12
# Sample size
n <- 100
num_samples <- 1000  # Number of samples to generate
# Generate random samples and calculate sample means
sample_means <- replicate(num_samples, mean(sqrt(rnorm(n, mean = population_mean, sd = population_stddev))))
# Create a histogram to visualize the sampling distribution of the sample mean
hist(sample_means, breaks = 30, prob = TRUE, col = "blue", main = "Sampling Distribution of Sample Mean for n = 100")
abline(v = population_mean, col = "red", lty = 2, lwd = 2)
legend("topright", legend = c("Sample Mean Distribution", "Population Mean"), col = c("blue", "red"), lty = c(1, 2))
# Add labels
xlabel <- "Sample Mean"
# Population parameters
population_mean <- 72
population_stddev <- 12
# Sample size
n <- 100
# Population parameters
population_mean <- 72
population_stddev <- 12
# Sample size
n <- 100
num_samples <- 100000  # Number of samples to generate
# Generate random samples and calculate sample means
sample_means <- replicate(num_samples, mean(sqrt(rnorm(n, mean = population_mean, sd = population_stddev))))
# Create a histogram to visualize the sampling distribution of the sample mean
hist(sample_means, breaks = 30, prob = TRUE, col = "blue", main = "Sampling Distribution of Sample Mean for n = 100")
abline(v = sqrt(population_mean), col = "red", lty = 2, lwd = 2)
legend("topright", legend = c("Sample Mean Distribution", "Population Mean"), col = c("blue", "red"), lty = c(1, 2))
# Population parameters
population_mean <- 72
population_stddev <- 12
# Sample size
n <- 100
num_samples <- 100000  # Number of samples to generate
# Generate random samples and calculate sample means
sample_means <- replicate(num_samples, mean(sqrt(rnorm(n, mean = population_mean, sd = population_stddev))))
# Create a histogram to visualize the sampling distribution of the sample mean
hist(sample_means, breaks = 30, prob = TRUE, col = "blue", main = "Sampling Distribution of Sample Mean for n = 100")
abline(v = mean(sample_means), col = "red", lty = 2, lwd = 2)
# Population parameters
population_mean <- 72
population_stddev <- 12
# Sample size
n <- 100
num_samples <- 100000  # Number of samples to generate
# Generate random samples and calculate sample means
sample_means <- replicate(num_samples, mean(sqrt(rnorm(n, mean = population_mean, sd = population_stddev))))
# Create a histogram to visualize the sampling distribution of the sample mean
hist(sample_means, breaks = 30, prob = TRUE, col = "blue", main = "Sampling Distribution of Sample Mean for n = 100")
abline(v = mean(sample_means), col = "red", lty = 2, lwd = 2)
curve(dnorm(x, mean=mean(sample_means), sd=sd(sample_means)), add = T)
# Population parameters
population_mean <- 72
population_stddev <- 12
# Sample size
n <- 100
num_samples <- 100000  # Number of samples to generate
plot(x, sqrt(dnorm(x, mean=72, sd= 12)))
# Sample size
n <- 100
num_samples <- 100000  # Number of samples to generate
x=seq(0,120, by=1)
plot(x, sqrt(dnorm(x, mean=72, sd= 12)))
# Generate random samples and calculate sample means, introducing sqrt for left skewness
sample_means <- replicate(num_samples, mean(sqrt(rnorm(n, mean = population_mean, sd = population_stddev))))
# Create a histogram to visualize the sampling distribution of the sample mean
hist(sample_means, breaks = 30, prob = TRUE, col = "blue", main = "Sampling Distribution of Sample Mean for n = 100")
abline(v = mean(sample_means), col = "red", lty = 2, lwd = 2)
curve(dnorm(x, mean=mean(sample_means), sd=sd(sample_means)), add = T)
# Population parameters
population_mean <- 72
population_stddev <- 12
# Sample size
n <- 100
num_samples <- 100000  # Number of samples to generate
x=seq(0,120, by=1)
plot(x, sqrt(dnorm(x, mean=72, sd= 12)))
# Generate random samples and calculate sample means, introducing sqrt for left skewness
sample_means <- replicate(num_samples, mean(sqrt(rnorm(n, mean = population_mean, sd = population_stddev))))
plot(x, sqrt(dnorm(x, mean=72, sd= 12)))
# Generate random samples and calculate sample means, introducing sqrt for left skewness
sample_means <- replicate(num_samples, mean(sqrt(rnorm(n, mean = population_mean, sd = population_stddev))))
# Create a histogram to visualize the sampling distribution of the sample mean
hist(sample_means^2, breaks = 30, prob = TRUE, col = "blue", main = "Sampling Distribution of Sample Mean for n = 100")
abline(v = mean(sample_means^2), col = "red", lty = 2, lwd = 2)
curve(dnorm(x, mean=mean(sample_means^2), sd=sd(sample_means^2)), add = T)
plot(x, sqrt(dnorm(x, mean=72, sd= 12)))
# Generate random samples and calculate sample means, introducing sqrt for left skewness
sample_means <- replicate(num_samples, mean(sqrt(rnorm(n, mean = population_mean, sd = population_stddev))))
# Create a histogram to visualize the sampling distribution of the sample mean
hist(sample_means^2, breaks = 10, prob = TRUE, col = "blue", main = "Sampling Distribution of Sample Mean for n = 100")
# Generate random samples and calculate sample means, introducing sqrt for left skewness
sample_means <- replicate(num_samples, mean(sqrt(rnorm(n, mean = population_mean, sd = population_stddev))))
# Create a histogram to visualize the sampling distribution of the sample mean
hist(sample_means^2, breaks = 100, prob = TRUE, col = "blue", main = "Sampling Distribution of Sample Mean for n = 100")
abline(v = mean(sample_means^2), col = "red", lty = 2, lwd = 2)
curve(dnorm(x, mean=mean(sample_means^2), sd=sd(sample_means^2)), add = T)
# Create a histogram to visualize the sampling distribution of the sample mean
hist(sample_means^2, breaks = 50, prob = TRUE, col = "blue", main = "Sampling Distribution of Sample Mean for n = 100")
abline(v = mean(sample_means^2), col = "red", lty = 2, lwd = 2)
curve(dnorm(x, mean=mean(sample_means^2), sd=sd(sample_means^2)), add = T)
legend("topright", legend = c("Sample Mean Distribution", "Population Mean"), col = c("blue", "red"), lty = c(1, 2))
# Add labels
xlabel <- "Sample Mean"
ylabel <- "Density"
title(main = "Sampling Distribution of Sample Mean for n = 100", xlab = xlabel, ylab = ylabel)
# Population parameters
population_mean <- 72
population_stddev <- 12
# Sample size
n <- 1
num_samples <- 100000  # Number of samples to generate
x=seq(0,120, by=1)
plot(x, sqrt(dnorm(x, mean=72, sd= 12)))
# Generate random samples and calculate sample means, introducing sqrt for left skewness
sample_means <- replicate(num_samples, mean(sqrt(rnorm(n, mean = population_mean, sd = population_stddev))))
# Create a histogram to visualize the sampling distribution of the sample mean
hist(sample_means^2, breaks = 50, prob = TRUE, col = "blue", main = "Sampling Distribution of Sample Mean for n = 100")
abline(v = mean(sample_means^2), col = "red", lty = 2, lwd = 2)
curve(dnorm(x, mean=mean(sample_means^2), sd=sd(sample_means^2)), add = T)
legend("topright", legend = c("Sample Mean Distribution", "Population Mean"), col = c("blue", "red"), lty = c(1, 2))
# Add labels
xlabel <- "Sample Mean"
ylabel <- "Density"
title(main = "Sampling Distribution of Sample Mean for n = 100", xlab = xlabel, ylab = ylabel)
# Population parameters
population_mean <- 72
population_stddev <- 12
# Sample size
n <- 90000
num_samples <- 100000  # Number of samples to generate
x=seq(0,120, by=1)
plot(x, sqrt(dnorm(x, mean=72, sd= 12)))
# Generate random samples and calculate sample means, introducing sqrt for left skewness
sample_means <- replicate(num_samples, mean(sqrt(rnorm(n, mean = population_mean, sd = population_stddev))))
# Set the parameters for the left-skewed distribution
mu <- 72     # Mean of the underlying normal distribution
sigma <- 12  # Standard deviation of the underlying normal distribution
# Generate random numbers from a log-normal distribution
n <- 1000  # Number of data points
skewed_data <- rlnorm(n, meanlog = log(mu) - 0.5 * log(1 + (sigma^2 / mu^2)), sdlog = sqrt(log(1 + (sigma^2 / mu^2))))
# Create a histogram to visualize the left-skewed distribution
hist(skewed_data, breaks = 30, main = "Left-Skewed Distribution", xlab = "Value")
knitr::opts_chunk$set(echo = TRUE)
Ma<-22.30
Mb<-25.91
Na<-43
Nb<-50
Sa<-6.88
Sb<-8.01
T<-(Ma - Mb)/sqrt((Sa^2/Na)+(Sb^2/Nb))
P_T_less <- pt(T, df = (Na + Nb - 2))
P_T_great <- 1 - pt(T, df = (Na + Nb - 2))
# Define a range of values for p
p_values <- seq(0, 1, length.out = 100)
# Calculate the likelihood function for each value of p
likelihood <- (1 - p_values)^2 * p_values
# Create a plot of the likelihood function
plot(p_values, likelihood, type = "l", xlab = "p (Probability of Success)", ylab = "Likelihood (L(p))", col = "red", lwd=2,
main = "Likelihood Function for the First Success on Observation 3")
Ma<-22.30
Mb<-25.91
Na<-43
Nb<-50
Sa<-6.88
Sb<-8.01
T<-(Ma - Mb)/sqrt((Sa^2/Na)+(Sb^2/Nb))
P_T_less <- pt(T, df = (Na + Nb - 2))
P_T_great <- 1 - pt(T, df = (Na + Nb - 2))
knitr::opts_chunk$set(echo = TRUE)
n <- 1200
pHat <- 624 / 1200
P0 <- 0.50
SE <- sqrt((P0 * (1 - P0)) / n)
z <- (pHat - P0) / SE
p_value <- 2 * pnorm(abs(z), lower.tail = FALSE)
Alpha <- 0.05
cat("Test Statistic (z):", z, "\n")
cat("P-Value:", p_value, "\n")
prop<- (sum(ds$life == 1))/60
prop
#4.4
ds <- read.table("Students.dat", header = T)
setwd(getwd())
getwd()
setwd("~/DSAI/HPC_final_project/exercise1/models")
setwd(getwd())
getwd()
data_bcast = read.csv("../results_def/bcast_complete.csv")
data_bcast = read.csv("../results_def/bcast_complete.csv")
# Correlation map
cor(data_bcast)
# Convert to factors the columns Allocation and Algorithm
data_bcast$Allocation = as.factor(data_bcast$Allocation)
data_bcast$Algorithm = as.factor(data_bcast$Algorithm)
head(data)
head(data_bcast)
# Create a linear model
model = lm(Avg.Latency.us. ~ . , data = data_bcast)
summary(model)
#try with a GAM
library(mgcv)
model_gam = gam(Avg.Latency.us. ~ Algorithm + Allocation + s(Processes) + MessageSize , data = data_bcast)
summary(model_gam)
# Create a linear model
model1 = lm(Avg.Latency.us. ~ Algorithm + Processes + MessageSize , data = data_bcast[data_bcast$Allocation == "core",])
summary(model1)
data_barrier = read.csv("../results_def/barrier_complete.csv")
# Convert to factors the columns Allocation and Algorithm
data_barrier$Allocation = as.factor(data_barrier$Allocation)
data_barrier$Algorithm = as.factor(data_barrier$Algorithm)
cor(data_barrier)
head(data_barrier)
# Create a linear model
model_barrier = lm(Avg.Latency.us. ~ Algorithm + Allocation + Processes , data = data_barrier)
summary(model_barrier)
#try with a GAM
library(mgcv)
model_gam_barrier = gam(Avg.Latency.us. ~ Algorithm + Allocation + s(Processes), data = data_barrier)
summary(model_gam_barrier)
# Consider only core allocation
model1 = lm(Avg.Latency.us. ~ Algorithm + Processes , data = data_barrier[data_barrier$Allocation == "core",])
summary(model1)
